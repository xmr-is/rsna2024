{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/markun/opt/miniconda3/envs/kaggle_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model = timm.create_model(\n",
    "    model_name=\"swin_large_patch4_window12_384.ms_in22k\", \n",
    "    pretrained=False,\n",
    "    features_only=False,\n",
    "    num_classes=10,\n",
    "    global_pool='avg'\n",
    ")\n",
    "\n",
    "# model.load_state_dict(\n",
    "#     torch.load(\"/Users/markun/git/rsna2024/kaggle/src/models/weights/swin_large_patch4_window12_384.ms_in22k_0.pt\",\n",
    "#                map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")))\n",
    "# for idx, (name, param) in enumerate(model.named_parameters()):\n",
    "#     print(f\"Parameter {idx}: Name = {name}, Value = {param}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleModel(\n",
       "  (model): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(30, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (layers): Sequential(\n",
       "      (0): SwinTransformerStage(\n",
       "        (downsample): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.004)\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.004)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.009)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.009)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.013)\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.013)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.017)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.017)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.022)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.022)\n",
       "          )\n",
       "          (2): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.026)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.026)\n",
       "          )\n",
       "          (3): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.030)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.030)\n",
       "          )\n",
       "          (4): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.035)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.035)\n",
       "          )\n",
       "          (5): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.039)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.039)\n",
       "          )\n",
       "          (6): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.043)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.043)\n",
       "          )\n",
       "          (7): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.048)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.048)\n",
       "          )\n",
       "          (8): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.052)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.052)\n",
       "          )\n",
       "          (9): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.057)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.057)\n",
       "          )\n",
       "          (10): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.061)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.061)\n",
       "          )\n",
       "          (11): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.065)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.065)\n",
       "          )\n",
       "          (12): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.070)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.070)\n",
       "          )\n",
       "          (13): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.074)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.074)\n",
       "          )\n",
       "          (14): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.078)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.078)\n",
       "          )\n",
       "          (15): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.083)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.083)\n",
       "          )\n",
       "          (16): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.087)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.087)\n",
       "          )\n",
       "          (17): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.091)\n",
       "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.091)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerStage(\n",
       "        (downsample): PatchMerging(\n",
       "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "          (reduction): Linear(in_features=3072, out_features=1536, bias=False)\n",
       "        )\n",
       "        (blocks): Sequential(\n",
       "          (0): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.096)\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.096)\n",
       "          )\n",
       "          (1): SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=1536, out_features=4608, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=1536, out_features=1536, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path1): DropPath(drop_prob=0.100)\n",
       "            (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (drop_path2): DropPath(drop_prob=0.100)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (scs_head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Linear(in_features=384, out_features=15, bias=True)\n",
       "    )\n",
       "    (flatten): Identity()\n",
       "  )\n",
       "  (nfn_head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Linear(in_features=384, out_features=30, bias=True)\n",
       "    )\n",
       "    (flatten): Identity()\n",
       "  )\n",
       "  (ss_head): ClassifierHead(\n",
       "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (4): GELU(approximate='none')\n",
       "      (5): Linear(in_features=384, out_features=30, bias=True)\n",
       "    )\n",
       "    (flatten): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "\n",
    "class SampleModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(SampleModel, self).__init__()\n",
    "        self.model = timm.create_model(\n",
    "            model_name=\"swin_large_patch4_window12_384.ms_in22k\", \n",
    "            pretrained=False,\n",
    "            in_chans=30,\n",
    "            features_only=False,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        self.scs_head = copy.deepcopy(self.model.head)\n",
    "        self.scs_head.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1536, out_features=768),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.0),\n",
    "            nn.Linear(in_features=768, out_features=384),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=384, out_features=15),\n",
    "        )\n",
    "\n",
    "        self.nfn_head = copy.deepcopy(self.model.head)\n",
    "        self.nfn_head.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1536, out_features=768),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.0),\n",
    "            nn.Linear(in_features=768, out_features=384),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=384, out_features=30),\n",
    "        )\n",
    "\n",
    "        self.ss_head = copy.deepcopy(self.model.head)\n",
    "        self.ss_head.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=1536, out_features=768),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(p=0.0),\n",
    "            nn.Linear(in_features=768, out_features=384),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(in_features=384, out_features=30),\n",
    "        )\n",
    "        \n",
    "        self.model.head = nn.Identity()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        logit = self.model(x)\n",
    "        scs_logit = self.scs_head(logit)\n",
    "        nfn_logit = self.nfn_head(logit)\n",
    "        ss_logit = self.ss_head(logit)\n",
    "        return scs_logit, nfn_logit, ss_logit\n",
    "\n",
    "model = SampleModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3351, 0.3327, 0.3322]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import softmax\n",
    "\n",
    "\n",
    "t = torch.Tensor([[-0.0017, -0.0087, -0.0104]])\n",
    "t.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 15]), torch.Size([1, 30]), torch.Size([1, 30]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_tensor = torch.rand([1,30,384,384])\n",
    "in_tensor.shape\n",
    "\n",
    "scs_out, nfn_out, ss_out = model(in_tensor)\n",
    "scs_out.shape, nfn_out.shape, ss_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>spinal_canal_stenosis_l1_l2</th>\n",
       "      <th>spinal_canal_stenosis_l2_l3</th>\n",
       "      <th>spinal_canal_stenosis_l3_l4</th>\n",
       "      <th>spinal_canal_stenosis_l4_l5</th>\n",
       "      <th>spinal_canal_stenosis_l5_s1</th>\n",
       "      <th>left_neural_foraminal_narrowing_l1_l2</th>\n",
       "      <th>left_neural_foraminal_narrowing_l2_l3</th>\n",
       "      <th>left_neural_foraminal_narrowing_l3_l4</th>\n",
       "      <th>left_neural_foraminal_narrowing_l4_l5</th>\n",
       "      <th>...</th>\n",
       "      <th>left_subarticular_stenosis_l1_l2</th>\n",
       "      <th>left_subarticular_stenosis_l2_l3</th>\n",
       "      <th>left_subarticular_stenosis_l3_l4</th>\n",
       "      <th>left_subarticular_stenosis_l4_l5</th>\n",
       "      <th>left_subarticular_stenosis_l5_s1</th>\n",
       "      <th>right_subarticular_stenosis_l1_l2</th>\n",
       "      <th>right_subarticular_stenosis_l2_l3</th>\n",
       "      <th>right_subarticular_stenosis_l3_l4</th>\n",
       "      <th>right_subarticular_stenosis_l4_l5</th>\n",
       "      <th>right_subarticular_stenosis_l5_s1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4003253</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4646740</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7143189</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8785691</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10728036</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>4282019580</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>4283570761</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>4284048608</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>4287160193</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Severe</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>4290709089</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>...</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "      <td>Normal/Mild</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1975 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        study_id spinal_canal_stenosis_l1_l2 spinal_canal_stenosis_l2_l3  \\\n",
       "0        4003253                 Normal/Mild                 Normal/Mild   \n",
       "1        4646740                 Normal/Mild                 Normal/Mild   \n",
       "2        7143189                 Normal/Mild                 Normal/Mild   \n",
       "3        8785691                 Normal/Mild                 Normal/Mild   \n",
       "4       10728036                 Normal/Mild                 Normal/Mild   \n",
       "...          ...                         ...                         ...   \n",
       "1970  4282019580                 Normal/Mild                 Normal/Mild   \n",
       "1971  4283570761                 Normal/Mild                 Normal/Mild   \n",
       "1972  4284048608                 Normal/Mild                 Normal/Mild   \n",
       "1973  4287160193                 Normal/Mild                    Moderate   \n",
       "1974  4290709089                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "     spinal_canal_stenosis_l3_l4 spinal_canal_stenosis_l4_l5  \\\n",
       "0                    Normal/Mild                 Normal/Mild   \n",
       "1                       Moderate                      Severe   \n",
       "2                    Normal/Mild                 Normal/Mild   \n",
       "3                    Normal/Mild                 Normal/Mild   \n",
       "4                    Normal/Mild                 Normal/Mild   \n",
       "...                          ...                         ...   \n",
       "1970                 Normal/Mild                 Normal/Mild   \n",
       "1971                 Normal/Mild                 Normal/Mild   \n",
       "1972                 Normal/Mild                      Severe   \n",
       "1973                 Normal/Mild                 Normal/Mild   \n",
       "1974                 Normal/Mild                 Normal/Mild   \n",
       "\n",
       "     spinal_canal_stenosis_l5_s1 left_neural_foraminal_narrowing_l1_l2  \\\n",
       "0                    Normal/Mild                           Normal/Mild   \n",
       "1                    Normal/Mild                           Normal/Mild   \n",
       "2                    Normal/Mild                           Normal/Mild   \n",
       "3                    Normal/Mild                           Normal/Mild   \n",
       "4                    Normal/Mild                           Normal/Mild   \n",
       "...                          ...                                   ...   \n",
       "1970                 Normal/Mild                           Normal/Mild   \n",
       "1971                 Normal/Mild                           Normal/Mild   \n",
       "1972                 Normal/Mild                           Normal/Mild   \n",
       "1973                 Normal/Mild                           Normal/Mild   \n",
       "1974                 Normal/Mild                           Normal/Mild   \n",
       "\n",
       "     left_neural_foraminal_narrowing_l2_l3  \\\n",
       "0                              Normal/Mild   \n",
       "1                              Normal/Mild   \n",
       "2                              Normal/Mild   \n",
       "3                              Normal/Mild   \n",
       "4                              Normal/Mild   \n",
       "...                                    ...   \n",
       "1970                           Normal/Mild   \n",
       "1971                           Normal/Mild   \n",
       "1972                           Normal/Mild   \n",
       "1973                           Normal/Mild   \n",
       "1974                           Normal/Mild   \n",
       "\n",
       "     left_neural_foraminal_narrowing_l3_l4  \\\n",
       "0                              Normal/Mild   \n",
       "1                              Normal/Mild   \n",
       "2                              Normal/Mild   \n",
       "3                              Normal/Mild   \n",
       "4                              Normal/Mild   \n",
       "...                                    ...   \n",
       "1970                           Normal/Mild   \n",
       "1971                           Normal/Mild   \n",
       "1972                           Normal/Mild   \n",
       "1973                           Normal/Mild   \n",
       "1974                           Normal/Mild   \n",
       "\n",
       "     left_neural_foraminal_narrowing_l4_l5  ...  \\\n",
       "0                                 Moderate  ...   \n",
       "1                                 Moderate  ...   \n",
       "2                              Normal/Mild  ...   \n",
       "3                                 Moderate  ...   \n",
       "4                              Normal/Mild  ...   \n",
       "...                                    ...  ...   \n",
       "1970                              Moderate  ...   \n",
       "1971                           Normal/Mild  ...   \n",
       "1972                           Normal/Mild  ...   \n",
       "1973                              Moderate  ...   \n",
       "1974                           Normal/Mild  ...   \n",
       "\n",
       "     left_subarticular_stenosis_l1_l2 left_subarticular_stenosis_l2_l3  \\\n",
       "0                         Normal/Mild                      Normal/Mild   \n",
       "1                         Normal/Mild                      Normal/Mild   \n",
       "2                         Normal/Mild                      Normal/Mild   \n",
       "3                         Normal/Mild                      Normal/Mild   \n",
       "4                         Normal/Mild                      Normal/Mild   \n",
       "...                               ...                              ...   \n",
       "1970                      Normal/Mild                      Normal/Mild   \n",
       "1971                      Normal/Mild                      Normal/Mild   \n",
       "1972                      Normal/Mild                      Normal/Mild   \n",
       "1973                      Normal/Mild                           Severe   \n",
       "1974                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "     left_subarticular_stenosis_l3_l4 left_subarticular_stenosis_l4_l5  \\\n",
       "0                         Normal/Mild                         Moderate   \n",
       "1                         Normal/Mild                           Severe   \n",
       "2                         Normal/Mild                      Normal/Mild   \n",
       "3                         Normal/Mild                      Normal/Mild   \n",
       "4                         Normal/Mild                      Normal/Mild   \n",
       "...                               ...                              ...   \n",
       "1970                      Normal/Mild                         Moderate   \n",
       "1971                      Normal/Mild                      Normal/Mild   \n",
       "1972                      Normal/Mild                           Severe   \n",
       "1973                         Moderate                         Moderate   \n",
       "1974                      Normal/Mild                      Normal/Mild   \n",
       "\n",
       "     left_subarticular_stenosis_l5_s1 right_subarticular_stenosis_l1_l2  \\\n",
       "0                         Normal/Mild                       Normal/Mild   \n",
       "1                         Normal/Mild                       Normal/Mild   \n",
       "2                         Normal/Mild                       Normal/Mild   \n",
       "3                         Normal/Mild                       Normal/Mild   \n",
       "4                         Normal/Mild                       Normal/Mild   \n",
       "...                               ...                               ...   \n",
       "1970                      Normal/Mild                       Normal/Mild   \n",
       "1971                      Normal/Mild                       Normal/Mild   \n",
       "1972                      Normal/Mild                       Normal/Mild   \n",
       "1973                      Normal/Mild                       Normal/Mild   \n",
       "1974                      Normal/Mild                       Normal/Mild   \n",
       "\n",
       "     right_subarticular_stenosis_l2_l3 right_subarticular_stenosis_l3_l4  \\\n",
       "0                          Normal/Mild                       Normal/Mild   \n",
       "1                             Moderate                          Moderate   \n",
       "2                          Normal/Mild                       Normal/Mild   \n",
       "3                          Normal/Mild                       Normal/Mild   \n",
       "4                          Normal/Mild                       Normal/Mild   \n",
       "...                                ...                               ...   \n",
       "1970                       Normal/Mild                          Moderate   \n",
       "1971                       Normal/Mild                       Normal/Mild   \n",
       "1972                       Normal/Mild                       Normal/Mild   \n",
       "1973                       Normal/Mild                          Moderate   \n",
       "1974                       Normal/Mild                       Normal/Mild   \n",
       "\n",
       "     right_subarticular_stenosis_l4_l5 right_subarticular_stenosis_l5_s1  \n",
       "0                          Normal/Mild                       Normal/Mild  \n",
       "1                             Moderate                       Normal/Mild  \n",
       "2                          Normal/Mild                       Normal/Mild  \n",
       "3                          Normal/Mild                       Normal/Mild  \n",
       "4                             Moderate                       Normal/Mild  \n",
       "...                                ...                               ...  \n",
       "1970                          Moderate                          Moderate  \n",
       "1971                       Normal/Mild                       Normal/Mild  \n",
       "1972                            Severe                       Normal/Mild  \n",
       "1973                          Moderate                       Normal/Mild  \n",
       "1974                       Normal/Mild                       Normal/Mild  \n",
       "\n",
       "[1975 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedGroupKFold\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/Users/markun/git/rsna2024/data/train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fold: 0\n",
    "train_study_id: \n",
    "  - 4003253\n",
    "  - 7143189\n",
    "valid_study_id:\n",
    "  - 4646740\n",
    "  - 8785691\n",
    "\"\"\"\n",
    "\n",
    "import yaml\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (trn_idx, val_idx) in enumerate(kf.split(df)):\n",
    "\n",
    "    print('#'*30)\n",
    "    print(f'start fold {fold}')\n",
    "    print('#'*30)\n",
    "    print(len(trn_idx), len(val_idx))\n",
    "\n",
    "    df_train = df.iloc[trn_idx]\n",
    "    df_valid = df.iloc[val_idx]\n",
    "    \n",
    "    train = df_train['study_id'].tolist() \n",
    "    valid = df_valid['study_id'].tolist()  \n",
    "\n",
    "    fold_info = {\n",
    "        'fold': fold,\n",
    "        'train_study_id': train,\n",
    "        'valid_study_id': valid\n",
    "    }\n",
    "\n",
    "    output_yaml = f'fold_{fold}.yaml'\n",
    "    with open(output_yaml, 'w') as yaml_file:\n",
    "        yaml.dump(fold_info, yaml_file, default_flow_style=False)\n",
    "\n",
    "    print(f\"YAML '{output_yaml}' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'beitv2_base_patch16_224',\n",
       " 'beitv2_large_patch16_224',\n",
       " 'botnet26t_256',\n",
       " 'botnet50ts_256',\n",
       " 'caformer_b36',\n",
       " 'caformer_m36',\n",
       " 'caformer_s18',\n",
       " 'caformer_s36',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_medium',\n",
       " 'coat_lite_medium_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_small',\n",
       " 'coat_tiny',\n",
       " 'coatnet_0_224',\n",
       " 'coatnet_0_rw_224',\n",
       " 'coatnet_1_224',\n",
       " 'coatnet_1_rw_224',\n",
       " 'coatnet_2_224',\n",
       " 'coatnet_2_rw_224',\n",
       " 'coatnet_3_224',\n",
       " 'coatnet_3_rw_224',\n",
       " 'coatnet_4_224',\n",
       " 'coatnet_5_224',\n",
       " 'coatnet_bn_0_rw_224',\n",
       " 'coatnet_nano_cc_224',\n",
       " 'coatnet_nano_rw_224',\n",
       " 'coatnet_pico_rw_224',\n",
       " 'coatnet_rmlp_0_rw_224',\n",
       " 'coatnet_rmlp_1_rw2_224',\n",
       " 'coatnet_rmlp_1_rw_224',\n",
       " 'coatnet_rmlp_2_rw_224',\n",
       " 'coatnet_rmlp_2_rw_384',\n",
       " 'coatnet_rmlp_3_rw_224',\n",
       " 'coatnet_rmlp_nano_rw_224',\n",
       " 'coatnext_nano_rw_224',\n",
       " 'convformer_b36',\n",
       " 'convformer_m36',\n",
       " 'convformer_s18',\n",
       " 'convformer_s36',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_atto',\n",
       " 'convnext_atto_ols',\n",
       " 'convnext_base',\n",
       " 'convnext_femto',\n",
       " 'convnext_femto_ols',\n",
       " 'convnext_large',\n",
       " 'convnext_large_mlp',\n",
       " 'convnext_nano',\n",
       " 'convnext_nano_ols',\n",
       " 'convnext_pico',\n",
       " 'convnext_pico_ols',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_tiny_hnf',\n",
       " 'convnext_xlarge',\n",
       " 'convnext_xxlarge',\n",
       " 'convnextv2_atto',\n",
       " 'convnextv2_base',\n",
       " 'convnextv2_femto',\n",
       " 'convnextv2_huge',\n",
       " 'convnextv2_large',\n",
       " 'convnextv2_nano',\n",
       " 'convnextv2_pico',\n",
       " 'convnextv2_small',\n",
       " 'convnextv2_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cs3darknet_focus_l',\n",
       " 'cs3darknet_focus_m',\n",
       " 'cs3darknet_focus_s',\n",
       " 'cs3darknet_focus_x',\n",
       " 'cs3darknet_l',\n",
       " 'cs3darknet_m',\n",
       " 'cs3darknet_s',\n",
       " 'cs3darknet_x',\n",
       " 'cs3edgenet_x',\n",
       " 'cs3se_edgenet_x',\n",
       " 'cs3sedarknet_l',\n",
       " 'cs3sedarknet_x',\n",
       " 'cs3sedarknet_xdw',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnet50d',\n",
       " 'cspresnet50w',\n",
       " 'cspresnext50',\n",
       " 'darknet17',\n",
       " 'darknet21',\n",
       " 'darknet53',\n",
       " 'darknetaa53',\n",
       " 'davit_base',\n",
       " 'davit_giant',\n",
       " 'davit_huge',\n",
       " 'davit_large',\n",
       " 'davit_small',\n",
       " 'davit_tiny',\n",
       " 'deit3_base_patch16_224',\n",
       " 'deit3_base_patch16_384',\n",
       " 'deit3_huge_patch14_224',\n",
       " 'deit3_large_patch16_224',\n",
       " 'deit3_large_patch16_384',\n",
       " 'deit3_medium_patch16_224',\n",
       " 'deit3_small_patch16_224',\n",
       " 'deit3_small_patch16_384',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenet264d',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn48b',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_nfnet_l3',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'eca_vovnet39b',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet200d',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'ecaresnext26t_32x4d',\n",
       " 'ecaresnext50t_32x4d',\n",
       " 'edgenext_base',\n",
       " 'edgenext_small',\n",
       " 'edgenext_small_rw',\n",
       " 'edgenext_x_small',\n",
       " 'edgenext_xx_small',\n",
       " 'efficientformer_l1',\n",
       " 'efficientformer_l3',\n",
       " 'efficientformer_l7',\n",
       " 'efficientformerv2_l',\n",
       " 'efficientformerv2_s0',\n",
       " 'efficientformerv2_s1',\n",
       " 'efficientformerv2_s2',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b0_g8_gn',\n",
       " 'efficientnet_b0_g16_evos',\n",
       " 'efficientnet_b0_gn',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_g8_gn',\n",
       " 'efficientnet_b3_gn',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_blur_b0',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_h_b5',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnet_x_b3',\n",
       " 'efficientnet_x_b5',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl',\n",
       " 'efficientvit_b0',\n",
       " 'efficientvit_b1',\n",
       " 'efficientvit_b2',\n",
       " 'efficientvit_b3',\n",
       " 'efficientvit_l1',\n",
       " 'efficientvit_l2',\n",
       " 'efficientvit_l3',\n",
       " 'efficientvit_m0',\n",
       " 'efficientvit_m1',\n",
       " 'efficientvit_m2',\n",
       " 'efficientvit_m3',\n",
       " 'efficientvit_m4',\n",
       " 'efficientvit_m5',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet19b_slim',\n",
       " 'ese_vovnet19b_slim_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'ese_vovnet39b_evos',\n",
       " 'ese_vovnet57b',\n",
       " 'ese_vovnet99b',\n",
       " 'eva02_base_patch14_224',\n",
       " 'eva02_base_patch14_448',\n",
       " 'eva02_base_patch16_clip_224',\n",
       " 'eva02_enormous_patch14_clip_224',\n",
       " 'eva02_large_patch14_224',\n",
       " 'eva02_large_patch14_448',\n",
       " 'eva02_large_patch14_clip_224',\n",
       " 'eva02_large_patch14_clip_336',\n",
       " 'eva02_small_patch14_224',\n",
       " 'eva02_small_patch14_336',\n",
       " 'eva02_tiny_patch14_224',\n",
       " 'eva02_tiny_patch14_336',\n",
       " 'eva_giant_patch14_224',\n",
       " 'eva_giant_patch14_336',\n",
       " 'eva_giant_patch14_560',\n",
       " 'eva_giant_patch14_clip_224',\n",
       " 'eva_large_patch14_196',\n",
       " 'eva_large_patch14_336',\n",
       " 'fastvit_ma36',\n",
       " 'fastvit_mci0',\n",
       " 'fastvit_mci1',\n",
       " 'fastvit_mci2',\n",
       " 'fastvit_s12',\n",
       " 'fastvit_sa12',\n",
       " 'fastvit_sa24',\n",
       " 'fastvit_sa36',\n",
       " 'fastvit_t8',\n",
       " 'fastvit_t12',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'flexivit_base',\n",
       " 'flexivit_large',\n",
       " 'flexivit_small',\n",
       " 'focalnet_base_lrf',\n",
       " 'focalnet_base_srf',\n",
       " 'focalnet_huge_fl3',\n",
       " 'focalnet_huge_fl4',\n",
       " 'focalnet_large_fl3',\n",
       " 'focalnet_large_fl4',\n",
       " 'focalnet_small_lrf',\n",
       " 'focalnet_small_srf',\n",
       " 'focalnet_tiny_lrf',\n",
       " 'focalnet_tiny_srf',\n",
       " 'focalnet_xlarge_fl3',\n",
       " 'focalnet_xlarge_fl4',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_050',\n",
       " 'ghostnet_100',\n",
       " 'ghostnet_130',\n",
       " 'ghostnetv2_100',\n",
       " 'ghostnetv2_130',\n",
       " 'ghostnetv2_160',\n",
       " 'gmixer_12_224',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_b16_224',\n",
       " 'gmlp_s16_224',\n",
       " 'gmlp_ti16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'halonet_h1',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hgnet_base',\n",
       " 'hgnet_small',\n",
       " 'hgnet_tiny',\n",
       " 'hgnetv2_b0',\n",
       " 'hgnetv2_b1',\n",
       " 'hgnetv2_b2',\n",
       " 'hgnetv2_b3',\n",
       " 'hgnetv2_b4',\n",
       " 'hgnetv2_b5',\n",
       " 'hgnetv2_b6',\n",
       " 'hiera_base_224',\n",
       " 'hiera_base_plus_224',\n",
       " 'hiera_huge_224',\n",
       " 'hiera_large_224',\n",
       " 'hiera_small_224',\n",
       " 'hiera_tiny_224',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w18_ssld',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w48_ssld',\n",
       " 'hrnet_w64',\n",
       " 'inception_next_base',\n",
       " 'inception_next_small',\n",
       " 'inception_next_tiny',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_035',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'lcnet_150',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'legacy_xception',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'levit_384_s8',\n",
       " 'levit_512',\n",
       " 'levit_512_s8',\n",
       " 'levit_512d',\n",
       " 'levit_conv_128',\n",
       " 'levit_conv_128s',\n",
       " 'levit_conv_192',\n",
       " 'levit_conv_256',\n",
       " 'levit_conv_256d',\n",
       " 'levit_conv_384',\n",
       " 'levit_conv_384_s8',\n",
       " 'levit_conv_512',\n",
       " 'levit_conv_512_s8',\n",
       " 'levit_conv_512d',\n",
       " 'maxvit_base_tf_224',\n",
       " 'maxvit_base_tf_384',\n",
       " 'maxvit_base_tf_512',\n",
       " 'maxvit_large_tf_224',\n",
       " 'maxvit_large_tf_384',\n",
       " 'maxvit_large_tf_512',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_base_rw_224',\n",
       " 'maxvit_rmlp_base_rw_384',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_tf_224',\n",
       " 'maxvit_small_tf_384',\n",
       " 'maxvit_small_tf_512',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_tiny_tf_224',\n",
       " 'maxvit_tiny_tf_384',\n",
       " 'maxvit_tiny_tf_512',\n",
       " 'maxvit_xlarge_tf_224',\n",
       " 'maxvit_xlarge_tf_384',\n",
       " 'maxvit_xlarge_tf_512',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'maxxvitv2_nano_rw_256',\n",
       " 'maxxvitv2_rmlp_base_rw_224',\n",
       " 'maxxvitv2_rmlp_base_rw_384',\n",
       " 'maxxvitv2_rmlp_large_rw_224',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b32_224',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l32_224',\n",
       " 'mixer_s16_224',\n",
       " 'mixer_s32_224',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mixnet_xxl',\n",
       " 'mnasnet_050',\n",
       " 'mnasnet_075',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_140',\n",
       " 'mnasnet_small',\n",
       " 'mobilenet_100',\n",
       " 'mobilenet_125',\n",
       " 'mobilenet_edgetpu_100',\n",
       " 'mobilenet_edgetpu_v2_l',\n",
       " 'mobilenet_edgetpu_v2_m',\n",
       " 'mobilenet_edgetpu_v2_s',\n",
       " 'mobilenet_edgetpu_v2_xs',\n",
       " 'mobilenetv2_035',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_075',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_075',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_rw',\n",
       " 'mobilenetv3_small_050',\n",
       " 'mobilenetv3_small_075',\n",
       " 'mobilenetv3_small_100',\n",
       " 'mobilenetv4_conv_aa_medium',\n",
       " 'mobilenetv4_conv_blur_medium',\n",
       " 'mobilenetv4_conv_large',\n",
       " 'mobilenetv4_conv_medium',\n",
       " 'mobilenetv4_conv_small',\n",
       " 'mobilenetv4_hybrid_large',\n",
       " 'mobilenetv4_hybrid_large_075',\n",
       " 'mobilenetv4_hybrid_medium',\n",
       " 'mobilenetv4_hybrid_medium_075',\n",
       " 'mobileone_s0',\n",
       " 'mobileone_s1',\n",
       " 'mobileone_s2',\n",
       " 'mobileone_s3',\n",
       " 'mobileone_s4',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_200',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_base_cls',\n",
       " 'mvitv2_huge_cls',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_large_cls',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'nasnetalarge',\n",
       " 'nest_base',\n",
       " 'nest_base_jx',\n",
       " 'nest_small',\n",
       " 'nest_small_jx',\n",
       " 'nest_tiny',\n",
       " 'nest_tiny_jx',\n",
       " 'nextvit_base',\n",
       " 'nextvit_large',\n",
       " 'nextvit_small',\n",
       " 'nf_ecaresnet26',\n",
       " 'nf_ecaresnet50',\n",
       " 'nf_ecaresnet101',\n",
       " 'nf_regnet_b0',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_regnet_b2',\n",
       " 'nf_regnet_b3',\n",
       " 'nf_regnet_b4',\n",
       " 'nf_regnet_b5',\n",
       " 'nf_resnet26',\n",
       " 'nf_resnet50',\n",
       " 'nf_resnet101',\n",
       " 'nf_seresnet26',\n",
       " 'nf_seresnet50',\n",
       " 'nf_seresnet101',\n",
       " 'nfnet_f0',\n",
       " 'nfnet_f1',\n",
       " 'nfnet_f2',\n",
       " 'nfnet_f3',\n",
       " 'nfnet_f4',\n",
       " 'nfnet_f5',\n",
       " 'nfnet_f6',\n",
       " 'nfnet_f7',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'poolformer_m36',\n",
       " 'poolformer_m48',\n",
       " 'poolformer_s12',\n",
       " 'poolformer_s24',\n",
       " 'poolformer_s36',\n",
       " 'poolformerv2_m36',\n",
       " 'poolformerv2_m48',\n",
       " 'poolformerv2_s12',\n",
       " 'poolformerv2_s24',\n",
       " 'poolformerv2_s36',\n",
       " 'pvt_v2_b0',\n",
       " 'pvt_v2_b1',\n",
       " 'pvt_v2_b2',\n",
       " 'pvt_v2_b2_li',\n",
       " 'pvt_v2_b3',\n",
       " 'pvt_v2_b4',\n",
       " 'pvt_v2_b5',\n",
       " 'regnetv_040',\n",
       " 'regnetv_064',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_004_tv',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_008_tv',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_040_sgn',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_080_tv',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnety_640',\n",
       " 'regnety_1280',\n",
       " 'regnety_2560',\n",
       " 'regnetz_005',\n",
       " 'regnetz_040',\n",
       " 'regnetz_040_h',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_b16_evos',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_c16_evos',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d8_evos',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repghostnet_050',\n",
       " 'repghostnet_058',\n",
       " 'repghostnet_080',\n",
       " 'repghostnet_100',\n",
       " 'repghostnet_111',\n",
       " 'repghostnet_130',\n",
       " 'repghostnet_150',\n",
       " 'repghostnet_200',\n",
       " 'repvgg_a0',\n",
       " 'repvgg_a1',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'repvgg_d2se',\n",
       " 'repvit_m0_9',\n",
       " 'repvit_m1',\n",
       " 'repvit_m1_0',\n",
       " 'repvit_m1_1',\n",
       " 'repvit_m1_5',\n",
       " 'repvit_m2',\n",
       " 'repvit_m2_3',\n",
       " 'repvit_m3',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net50d',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2net101d',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet10t',\n",
       " 'resnet14t',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_clip',\n",
       " 'resnet50_clip_gap',\n",
       " 'resnet50_gn',\n",
       " 'resnet50_mlp',\n",
       " 'resnet50c',\n",
       " 'resnet50d',\n",
       " 'resnet50s',\n",
       " 'resnet50t',\n",
       " 'resnet50x4_clip',\n",
       " 'resnet50x4_clip_gap',\n",
       " 'resnet50x16_clip',\n",
       " 'resnet50x16_clip_gap',\n",
       " 'resnet50x64_clip',\n",
       " 'resnet50x64_clip_gap',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101_clip',\n",
       " 'resnet101_clip_gap',\n",
       " 'resnet101c',\n",
       " 'resnet101d',\n",
       " 'resnet101s',\n",
       " 'resnet152',\n",
       " 'resnet152c',\n",
       " 'resnet152d',\n",
       " 'resnet152s',\n",
       " 'resnet200',\n",
       " 'resnet200d',\n",
       " 'resnetaa34d',\n",
       " 'resnetaa50',\n",
       " 'resnetaa50d',\n",
       " 'resnetaa101d',\n",
       " 'resnetblur18',\n",
       " 'resnetblur50',\n",
       " 'resnetblur50d',\n",
       " 'resnetblur101d',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50d',\n",
       " 'resnetv2_50d_evos',\n",
       " 'resnetv2_50d_frn',\n",
       " 'resnetv2_50d_gn',\n",
       " 'resnetv2_50t',\n",
       " 'resnetv2_50x1_bit',\n",
       " 'resnetv2_50x3_bit',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101d',\n",
       " 'resnetv2_101x1_bit',\n",
       " 'resnetv2_101x3_bit',\n",
       " 'resnetv2_152',\n",
       " 'resnetv2_152d',\n",
       " 'resnetv2_152x2_bit',\n",
       " 'resnetv2_152x4_bit',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_32x16d',\n",
       " 'resnext101_32x32d',\n",
       " 'resnext101_64x4d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'rexnet_300',\n",
       " 'rexnetr_100',\n",
       " 'rexnetr_130',\n",
       " 'rexnetr_150',\n",
       " 'rexnetr_200',\n",
       " 'rexnetr_300',\n",
       " 'samvit_base_patch16',\n",
       " 'samvit_base_patch16_224',\n",
       " 'samvit_huge_patch16',\n",
       " 'samvit_large_patch16',\n",
       " 'sebotnet33ts_256',\n",
       " 'sedarknet21',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'selecsls84',\n",
       " 'semnasnet_050',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'semnasnet_140',\n",
       " 'senet154',\n",
       " 'sequencer2d_l',\n",
       " 'sequencer2d_m',\n",
       " 'sequencer2d_s',\n",
       " 'seresnet18',\n",
       " 'seresnet33ts',\n",
       " 'seresnet34',\n",
       " 'seresnet50',\n",
       " 'seresnet50t',\n",
       " 'seresnet101',\n",
       " 'seresnet152',\n",
       " 'seresnet152d',\n",
       " 'seresnet200d',\n",
       " 'seresnet269d',\n",
       " 'seresnetaa50d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'seresnext101_32x4d',\n",
       " 'seresnext101_32x8d',\n",
       " 'seresnext101_64x4d',\n",
       " 'seresnext101d_32x8d',\n",
       " 'seresnextaa101d_32x8d',\n",
       " 'seresnextaa201d_32x8d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnet50',\n",
       " 'skresnet50d',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_s3_base_224',\n",
       " 'swin_s3_small_224',\n",
       " 'swin_s3_tiny_224',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swinv2_base_window8_256',\n",
       " 'swinv2_base_window12_192',\n",
       " 'swinv2_base_window12to16_192to256',\n",
       " 'swinv2_base_window12to24_192to384',\n",
       " 'swinv2_base_window16_256',\n",
       " 'swinv2_cr_base_224',\n",
       " 'swinv2_cr_base_384',\n",
       " 'swinv2_cr_base_ns_224',\n",
       " 'swinv2_cr_giant_224',\n",
       " 'swinv2_cr_giant_384',\n",
       " 'swinv2_cr_huge_224',\n",
       " 'swinv2_cr_huge_384',\n",
       " 'swinv2_cr_large_224',\n",
       " 'swinv2_cr_large_384',\n",
       " 'swinv2_cr_small_224',\n",
       " 'swinv2_cr_small_384',\n",
       " 'swinv2_cr_small_ns_224',\n",
       " 'swinv2_cr_small_ns_256',\n",
       " 'swinv2_cr_tiny_224',\n",
       " 'swinv2_cr_tiny_384',\n",
       " 'swinv2_cr_tiny_ns_224',\n",
       " 'swinv2_large_window12_192',\n",
       " 'swinv2_large_window12to16_192to256',\n",
       " 'swinv2_large_window12to24_192to384',\n",
       " 'swinv2_small_window8_256',\n",
       " 'swinv2_small_window16_256',\n",
       " 'swinv2_tiny_window8_256',\n",
       " 'swinv2_tiny_window16_256',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_xl',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tiny_vit_5m_224',\n",
       " 'tiny_vit_11m_224',\n",
       " 'tiny_vit_21m_224',\n",
       " 'tiny_vit_21m_384',\n",
       " 'tiny_vit_21m_512',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_b_patch16_224',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_m',\n",
       " 'tresnet_v2_l',\n",
       " 'tresnet_xl',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'visformer_tiny',\n",
       " 'vit_base_mci_224',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch14_dinov2',\n",
       " 'vit_base_patch14_reg4_dinov2',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_clip_224',\n",
       " 'vit_base_patch16_clip_384',\n",
       " 'vit_base_patch16_clip_quickgelu_224',\n",
       " 'vit_base_patch16_gap_224',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_reg4_gap_256',\n",
       " 'vit_base_patch16_rope_reg1_gap_256',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch16_siglip_224',\n",
       " 'vit_base_patch16_siglip_256',\n",
       " 'vit_base_patch16_siglip_384',\n",
       " 'vit_base_patch16_siglip_512',\n",
       " 'vit_base_patch16_siglip_gap_224',\n",
       " 'vit_base_patch16_siglip_gap_256',\n",
       " 'vit_base_patch16_siglip_gap_384',\n",
       " 'vit_base_patch16_siglip_gap_512',\n",
       " 'vit_base_patch16_xp_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_clip_224',\n",
       " 'vit_base_patch32_clip_256',\n",
       " 'vit_base_patch32_clip_384',\n",
       " 'vit_base_patch32_clip_448',\n",
       " 'vit_base_patch32_clip_quickgelu_224',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_betwixt_patch16_gap_256',\n",
       " 'vit_betwixt_patch16_reg1_gap_256',\n",
       " 'vit_betwixt_patch16_reg4_gap_256',\n",
       " 'vit_betwixt_patch16_rope_reg4_gap_256',\n",
       " 'vit_betwixt_patch32_clip_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_clip_224',\n",
       " 'vit_giant_patch14_dinov2',\n",
       " 'vit_giant_patch14_reg4_dinov2',\n",
       " 'vit_giant_patch16_gap_224',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_gigantic_patch14_clip_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_clip_224',\n",
       " 'vit_huge_patch14_clip_336',\n",
       " 'vit_huge_patch14_clip_378',\n",
       " 'vit_huge_patch14_clip_quickgelu_224',\n",
       " 'vit_huge_patch14_clip_quickgelu_378',\n",
       " 'vit_huge_patch14_gap_224',\n",
       " 'vit_huge_patch14_xp_224',\n",
       " 'vit_huge_patch16_gap_448',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_clip_224',\n",
       " 'vit_large_patch14_clip_336',\n",
       " 'vit_large_patch14_clip_quickgelu_224',\n",
       " 'vit_large_patch14_clip_quickgelu_336',\n",
       " 'vit_large_patch14_dinov2',\n",
       " 'vit_large_patch14_reg4_dinov2',\n",
       " 'vit_large_patch14_xp_224',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch16_siglip_256',\n",
       " 'vit_large_patch16_siglip_384',\n",
       " 'vit_large_patch16_siglip_gap_256',\n",
       " 'vit_large_patch16_siglip_gap_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_little_patch16_reg1_gap_256',\n",
       " 'vit_little_patch16_reg4_gap_256',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "timm.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cosine_annealing_with_warmup(step, warmup_steps, total_steps, lr_max, lr_min):\n",
    "    if step < warmup_steps:\n",
    "        return lr_max * (step / warmup_steps)\n",
    "    else:\n",
    "        progress = (step - warmup_steps) / (total_steps - warmup_steps)\n",
    "        return lr_min + 0.5 * (lr_max - lr_min) * (1 + np.cos(np.pi * progress))\n",
    "\n",
    "# \n",
    "lr_max = 0.1  # \n",
    "lr_min = 0.01  # \n",
    "warmup_steps = 100  # \n",
    "total_steps = 500  # \n",
    "\n",
    "# \n",
    "steps = np.arange(total_steps)\n",
    "lrs = [cosine_annealing_with_warmup(step, warmup_steps, total_steps, lr_max, lr_min) for step in steps]\n",
    "\n",
    "# \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, lrs, label='Cosine Annealing with Warmup', color='b')\n",
    "plt.axvline(x=warmup_steps, color='r', linestyle='--', label='Warmup End')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.title('Cosine Annealing with Warmup')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Weight File Loaded !!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RSNA2024_ViT_HipOA(\n",
       "  (model): VisionTransformer(\n",
       "    (conv_proj): Conv2d(30, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (encoder): Encoder(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (layers): Sequential(\n",
       "        (encoder_layer_0): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_1): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_2): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_3): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_4): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_5): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_6): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_7): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_8): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_9): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_10): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (encoder_layer_11): EncoderBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (self_attention): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): MLPBlock(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.1, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (heads): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=384, bias=True)\n",
       "      (1): Linear(in_features=384, out_features=75, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "class RSNA2024_ViT_HipOA(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "    ) -> None:\n",
    "        super(RSNA2024_ViT_HipOA, self).__init__()\n",
    "        self.model = models.vit_b_16()\n",
    "        self.spine_classifier = [\n",
    "            nn.Linear(in_features=768,\n",
    "                      out_features=384,\n",
    "                      bias=True),\n",
    "            nn.Linear(in_features=384,\n",
    "                      out_features=75)\n",
    "        ]\n",
    "        self.init_params()\n",
    "        self.model.heads = nn.Sequential(*self.spine_classifier)\n",
    "    \n",
    "\n",
    "    def init_params(self) -> None:\n",
    "        self.init_final_layer()\n",
    "        self.load_pretrained_weight()\n",
    "        self.change_first_layer()\n",
    "        self.set_dropout_rate()\n",
    "\n",
    "    def change_first_layer(self) -> None:\n",
    "        self.model.conv_proj = nn.Conv2d(\n",
    "            30, \n",
    "            768, \n",
    "            kernel_size=(16, 16), \n",
    "            stride=(16, 16)\n",
    "        )\n",
    "        param = self.model.state_dict()\n",
    "        param['conv_proj.weight'] = nn.Parameter(\n",
    "            torch.randn(768,30,16,16)\n",
    "        )\n",
    "    \n",
    "    def init_final_layer(self) -> None:\n",
    "        self.model.heads = nn.Sequential(\n",
    "            nn.Linear(in_features=768,\n",
    "                      out_features=7)\n",
    "        )\n",
    "\n",
    "    def set_dropout_rate(self) -> None:\n",
    "        for layer in self.model.modules():\n",
    "            if isinstance(layer, nn.Dropout):\n",
    "                layer.p = 0.1\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "    def load_pretrained_weight(self) -> None:\n",
    "        try:\n",
    "            self.model.load_state_dict(\n",
    "                torch.load(\n",
    "                    f'/Users/markun/git/rsna2024/kaggle/src/models/weights/vit_weight.pth',\n",
    "                    map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "                )\n",
    "            )\n",
    "            print(\"- Weight File Loaded !!\")\n",
    "        except Exception as e:\n",
    "            print(e, \"- Weight File Not Found !!\")\n",
    "    \n",
    "    def forward(self, x) -> torch.Tensor:\n",
    "        spine_logits = self.model(x)\n",
    "        return spine_logits\n",
    "model = RSNA2024_ViT_HipOA()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.class_token True\n",
      "model.conv_proj.weight True\n",
      "model.conv_proj.bias True\n",
      "model.encoder.pos_embedding True\n",
      "model.encoder.layers.encoder_layer_0.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_0.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_0.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_0.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_0.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_0.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_0.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_0.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_0.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_0.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_0.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_0.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_1.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_1.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_1.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_1.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_1.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_1.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_1.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_1.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_1.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_1.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_1.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_1.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_2.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_2.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_2.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_2.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_2.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_2.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_2.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_2.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_2.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_2.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_2.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_2.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_3.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_3.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_3.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_3.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_3.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_3.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_3.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_3.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_3.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_3.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_3.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_3.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_4.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_4.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_4.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_4.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_4.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_4.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_4.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_4.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_4.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_4.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_4.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_4.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_5.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_5.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_5.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_5.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_5.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_5.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_5.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_5.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_5.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_5.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_5.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_5.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_6.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_6.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_6.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_6.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_6.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_6.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_6.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_6.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_6.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_6.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_6.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_6.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_7.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_7.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_7.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_7.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_7.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_7.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_7.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_7.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_7.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_7.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_7.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_7.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_8.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_8.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_8.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_8.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_8.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_8.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_8.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_8.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_8.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_8.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_8.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_8.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_9.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_9.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_9.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_9.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_9.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_9.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_9.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_9.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_9.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_9.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_9.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_9.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_10.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_10.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_10.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_10.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_10.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_10.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_10.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_10.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_10.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_10.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_10.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_10.mlp.3.bias True\n",
      "model.encoder.layers.encoder_layer_11.ln_1.weight True\n",
      "model.encoder.layers.encoder_layer_11.ln_1.bias True\n",
      "model.encoder.layers.encoder_layer_11.self_attention.in_proj_weight True\n",
      "model.encoder.layers.encoder_layer_11.self_attention.in_proj_bias True\n",
      "model.encoder.layers.encoder_layer_11.self_attention.out_proj.weight True\n",
      "model.encoder.layers.encoder_layer_11.self_attention.out_proj.bias True\n",
      "model.encoder.layers.encoder_layer_11.ln_2.weight True\n",
      "model.encoder.layers.encoder_layer_11.ln_2.bias True\n",
      "model.encoder.layers.encoder_layer_11.mlp.0.weight True\n",
      "model.encoder.layers.encoder_layer_11.mlp.0.bias True\n",
      "model.encoder.layers.encoder_layer_11.mlp.3.weight True\n",
      "model.encoder.layers.encoder_layer_11.mlp.3.bias True\n",
      "model.encoder.ln.weight True\n",
      "model.encoder.ln.bias True\n",
      "model.heads.0.weight True\n",
      "model.heads.0.bias True\n",
      "model.heads.1.weight True\n",
      "model.heads.1.bias True\n"
     ]
    }
   ],
   "source": [
    "for name, p in model.named_parameters():\n",
    "    print(name, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
